#!/bin/bash
set -e

echo "ðŸš€ Starting Unified Hazard Detection Service..."
echo "ðŸ³ Container Environment: ${NODE_ENV:-production}"
echo "ðŸŒ Web Server Port: ${WEB_PORT:-3000}"
echo "ðŸ API Server Port: ${API_PORT:-8000}"

# Function to cleanup on exit
cleanup() {
    echo "ðŸ›‘ Shutting down all services..."
    pkill -f "uvicorn" 2>/dev/null || true
    pkill -f "node" 2>/dev/null || true
    pkill -f "pm2" 2>/dev/null || true
    exit 0
}

# Set up signal handlers
trap cleanup SIGTERM SIGINT EXIT

# Step 1: Run intelligent model selection
echo "ðŸ§  Running intelligent CPU detection and model selection..."
cd /app
python3 /app/scripts/detect-cpu-and-select-model.py

# Load the generated model configuration
if [ -f "/app/.env.model" ]; then
    echo "ðŸ“‹ Loading model configuration..."
    export $(cat /app/.env.model | grep -v '^#' | xargs)
    echo "âœ… Selected Backend: ${MODEL_BACKEND}"
    echo "ðŸ“ Model Directory: ${MODEL_DIR}"
else
    echo "âš ï¸ No model configuration found, using defaults..."
    export MODEL_BACKEND=pytorch
    export MODEL_DIR=/app/models/pytorch
    export PYTORCH_MODEL_PATH=/app/models/pytorch/best.pt
fi

# Step 2: Update API app configuration based on selection
echo "âš™ï¸ Configuring API service for ${MODEL_BACKEND} backend..."

# Set common environment variables
export PYTHONPATH=/app
export API_URL=http://localhost:${API_PORT:-8000}
export WEB_PORT=${WEB_PORT:-3000}
export API_PORT=${API_PORT:-8000}

# Step 3: Start FastAPI service on configured API port
echo "ðŸ Starting FastAPI (${MODEL_BACKEND} backend) on port ${API_PORT}..."
cd /app
uvicorn api.app:app --host 0.0.0.0 --port ${API_PORT} --workers 1 &
API_PID=$!

# Wait for API to be ready
echo "â³ Waiting for API service to start..."
for i in {1..30}; do
    if curl -f http://localhost:${API_PORT}/health >/dev/null 2>&1; then
        echo "âœ… API service is ready!"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "âŒ API service failed to start within 30 seconds"
        exit 1
    fi
    sleep 1
done

# Step 4: Start Express web server
echo "ðŸŒ Starting Express web server on port ${WEB_PORT}..."
cd /app/server/routes

if [ -f "server.js" ]; then
    # Use the full-featured server with authentication
    API_URL=http://localhost:${API_PORT} PORT=${WEB_PORT} node server.js &
    WEB_PID=$!
elif [ -f "simple-server.js" ]; then
    # Fallback to simple server
    echo "âš ï¸ Using simple server (full server.js not found)"
    API_URL=http://localhost:${API_PORT} PORT=${WEB_PORT} node simple-server.js &
    WEB_PID=$!
else
    echo "âŒ No web server found in $(pwd)"
    echo "ðŸ“ Available files:"
    ls -la
    exit 1
fi

# Step 5: Health check and monitoring
echo "ðŸ¥ Starting health monitoring..."
for i in {1..20}; do
    if curl -f http://localhost:${WEB_PORT}/health >/dev/null 2>&1; then
        echo "âœ… Web server is ready!"
        break
    fi
    if [ $i -eq 20 ]; then
        echo "âŒ Web server failed to start within 20 seconds"
        exit 1
    fi
    sleep 1
done

echo "ðŸŽ‰ All services started successfully!"
echo "ðŸ“Š Service Status:"
echo "   ðŸ FastAPI (AI Backend): http://localhost:${API_PORT} (PID: $API_PID)"
echo "   ðŸŒ Web Server: http://localhost:${WEB_PORT} (PID: $WEB_PID)"
echo "   ðŸ§  AI Backend: ${MODEL_BACKEND}"
echo "   ðŸ“ Model Path: ${MODEL_DIR}"

# Create a simple health check endpoint info
cat > /tmp/service-info.json << EOL
{
  "status": "running",
  "services": {
    "api": {
      "url": "http://localhost:${API_PORT}",
      "pid": $API_PID,
      "backend": "${MODEL_BACKEND}",
      "model_path": "${MODEL_DIR}"
    },
    "web": {
      "url": "http://localhost:${WEB_PORT}",
      "pid": $WEB_PID
    }
  },
  "started_at": "$(date -Iseconds)"
}
EOL

echo "ðŸ”„ Services are running. Press Ctrl+C to stop."

# Wait for both processes
wait
