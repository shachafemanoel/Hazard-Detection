{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "גרסת Python שלך: 3.9.6 (default, Nov 11 2024, 03:15:39) \n",
      "[Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "\n",
      "⚠️ גרסת Python שלך היא מתחת ל-3.10. כדי להתקין TensorFlow==2.19.0 (דרוש על ידי tf_keras), מומלץ לעדכן לגרסת Python 3.10 או 3.11.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"גרסת Python שלך:\", sys.version)\n",
    "\n",
    "# בדיקה אם גרסת Python מתחת ל-3.10\n",
    "if sys.version_info < (3, 10):\n",
    "    print(\"\\n⚠️ גרסת Python שלך היא מתחת ל-3.10. כדי להתקין TensorFlow==2.19.0 (דרוש על ידי tf_keras), מומלץ לעדכן לגרסת Python 3.10 או 3.11.\")\n",
    "else:\n",
    "    print(\"\\nגרסת Python שלך מתאימה, אך עדיין יכול להיות שיש קונפליקטים נוספים בתלויות.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מעדכן את onnx2tf לגרסה האחרונה...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnx2tf in /Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages (1.20.0)\n",
      "onnx2tf עודכן בהצלחה!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def upgrade_package(package_name):\n",
    "    try:\n",
    "        print(f\"מעדכן את {package_name} לגרסה האחרונה...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package_name])\n",
    "        print(f\"{package_name} עודכן בהצלחה!\\n\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ישנה בעיה בעדכון {package_name}: {e}\")\n",
    "\n",
    "# עדכון onnx2tf\n",
    "upgrade_package(\"onnx2tf\")\n",
    "\n",
    "# לדוגמה, אם תרצה לעדכן גם את ultralytics:\n",
    "# upgrade_package(\"ultralytics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99 🚀 Python-3.9.6 torch-2.2.2 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'road_damage_detection_last_version.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.3 MB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ai-edge-litert>=1.2.0 (from versions: 1.0.0, 1.0.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for ai-edge-litert>=1.2.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"ai-edge-litert>=1.2.0\" \"onnx2tf>=1.26.3\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ai-edge-litert>=1.2.0 (from versions: 1.0.0, 1.0.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"ai-edge-litert>=1.2.0\" \"onnx2tf>=1.26.3\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache-dir \"ai-edge-litert>=1.2.0\" \"onnx2tf>=1.26.3\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.16.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: No matching distribution found for ai-edge-litert>=1.2.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 6.1s, saved as 'road_damage_detection_last_version.onnx' (10.2 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.20.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1743440525.078905  891870 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1743440525.080015  891870 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "W0000 00:00:1743440543.400568  891870 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1743440543.400590  891870 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 153.7s, saved as 'road_damage_detection_last_version_saved_model' (26.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.16.2...\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success ✅ 30.1s, saved as 'road_damage_detection_last_version.pb' (10.6 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow Decision Forests 1.9.0 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.16.2 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m starting export with tensorflowjs 4.22.0...\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m output node names: Identity:0,model_133/tf.math.top_k/TopKV2:0\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m running 'tensorflowjs_converter --input_format=tf_frozen_model  --output_node_names=Identity:0,model_133/tf.math.top_k/TopKV2:0 \"road_damage_detection_last_version.pb\" \"road_damage_detection_last_version_web_model\"'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "WARNING:root:TensorFlow Decision Forests 1.9.0 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.16.2 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight model_133/tf.tensor_scatter_nd_update_2/TensorScatterUpdate/indices with shape (1, 1) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_4/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_10/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_5/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_11/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_6/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_12/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_12/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_12/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_12/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_3/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_7/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_2/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_6/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.tensor_scatter_nd_update/TensorScatterUpdate/indices with shape (1500, 2, 2) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.tensor_scatter_nd_update_1/TensorScatterUpdate/indices with shape (1500, 2, 2) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_13/StridedSlice/begin with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_13/StridedSlice/end with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_13/StridedSlice/strides with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_10/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_10/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_10/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_4/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_14/StridedSlice/begin with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_14/StridedSlice/end with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_14/StridedSlice/strides with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_16/StridedSlice/begin with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_16/StridedSlice/end with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_16/StridedSlice/strides with shape (2,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_1/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_5/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.compat.v1.pad_7/PadV2/constant_values with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.compat.v1.pad_8/PadV2/constant_values with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.compat.v1.gather_8/GatherV2/indices with shape (1,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_20/StridedSlice/begin with shape (1,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_20/StridedSlice/end with shape (1,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_20/StridedSlice/strides with shape (1,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.math.less_7/Less/y with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.__operators__.getitem_13/strided_slice with shape () and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_9/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_9/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_9/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_6/StridedSlice/begin with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_6/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_6/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_8/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_8/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_8/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_4/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_4/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_4/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_2/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_2/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_2/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_1/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_1/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_1/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_3/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_3/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_3/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_5/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_5/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_5/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_7/StridedSlice/begin with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_7/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_7/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_11/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_11/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight model_133/tf.strided_slice_11/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m export success ✅ 13.9s, saved as 'road_damage_detection_last_version_web_model' (11.0 MB)\n",
      "\n",
      "Export complete (198.5s)\n",
      "Results saved to \u001b[1m/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=road_damage_detection_last_version_web_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=road_damage_detection_last_version_web_model imgsz=640 data=/workspace/RDD2022-3/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'road_damage_detection_last_version_web_model'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# טען את מודל ה-pt\n",
    "model = YOLO('road_damage_detection_last_version.pt')\n",
    "\n",
    "# נסה את הפרמטר nms=True (או include_nms=True), תלוי בגירסה\n",
    "# אם אתה על גירסה חדשה מאוד וזה לא עובד - ייתכן שהסירו את התמיכה לחלוטין\n",
    "model.export(\n",
    "    format='tfjs',\n",
    "    imgsz=640,\n",
    "    nms=True  # או: include_nms=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"BQvvxKrJPoAaNkv4ZXlr\")\n",
    "project = rf.workspace(\"hh-clsza\").project(\"hh-nkpc0\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov12\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.85 🚀 Python-3.9.6 torch-2.2.2 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.pt' with input shape (1, 3, 544, 544) BCHW and output shape(s) (1, 15, 6069) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.12.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.6s, saved as '/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx' (10.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.20.0...\n",
      "\u001b[31mERROR:\u001b[0m The trace log is below.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py\", line 310, in print_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py\", line 383, in inverted_operation_enable_disable_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py\", line 53, in get_replacement_parameter_wrapper_func\n",
      "    func(*args, **kwargs)\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/onnx2tf/ops/Resize.py\", line 417, in make_node\n",
      "    resized_tensor = Lambda(\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1044, in __call__\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/keras/layers/core.py\", line 913, in call\n",
      "    tracked_weights = set(v.ref() for v in self.weights)\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py\", line 1142, in upsampling2d_nearest\n",
      "    return tf.compat.v1.image.resize_nearest_neighbor(\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/image_ops_impl.py\", line 4758, in resize_nearest_neighbor\n",
      "    date=None,\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 3857, in resize_nearest_neighbor\n",
      "    _op._get_attr_bool(\"half_pixel_centers\"))\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 3895, in resize_nearest_neighbor_eager_fallback\n",
      "    4-D with shape `[batch, height, width, channels]`.\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py\", line 254, in args_to_matching_eager\n",
      "    # picked the wrong type.\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 1642, in convert_to_tensor\n",
      "    feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py\", line 344, in _constant_tensor_conversion_function\n",
      "    raise ValueError(\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py\", line 268, in constant\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py\", line 280, in _constant_impl\n",
      "    def _constant_impl(\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py\", line 305, in _constant_eager_impl\n",
      "    if shape == t.shape:\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n",
      "    try:\n",
      "  File \"/Users/shachafemanoel/Library/Python/3.9/lib/python/site-packages/keras/engine/keras_tensor.py\", line 283, in __array__\n",
      "TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(1, 17, 17, 256), dtype=tf.float32, name=None), name='tf.math.multiply_1843/Mul:0', description=\"created by layer 'tf.math.multiply_1843'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
      "\n",
      "\u001b[31mERROR:\u001b[0m input_onnx_file_path: /Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx\n",
      "\u001b[31mERROR:\u001b[0m onnx_op_name: /model.9/Resize\n",
      "\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n",
      "\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n",
      "\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n",
      "\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py:310\u001b[0m, in \u001b[0;36mprint_node_info.<locals>.print_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_log_level() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m LOG_LEVELS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py:383\u001b[0m, in \u001b[0;36minverted_operation_enable_disable.<locals>.inverted_operation_enable_disable_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minverted_operation_enable_disable_wrapper_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 383\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    The output_shape_trans stores the result of determining\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    whether the final output shape of the connected OP differs between ONNX and TensorFlow.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    False: No transposition\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py:53\u001b[0m, in \u001b[0;36mget_replacement_parameter.<locals>.get_replacement_parameter_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop_rep_params\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m         replacement_parameter \\\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m replacement_parameter \u001b[38;5;129;01min\u001b[39;00m replacement_parameters \\\n\u001b[1;32m     51\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m replacement_parameter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m op_name\n\u001b[1;32m     52\u001b[0m     ]\n\u001b[0;32m---> 53\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/ops/Resize.py:417\u001b[0m, in \u001b[0;36mmake_node\u001b[0;34m(graph_node, tf_layers_dict, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m half_pixel_centers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m resized_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_resize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malign_corners\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhalf_pixel_centers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m tf_op_type \u001b[38;5;241m=\u001b[39m tf_resize\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/keras/engine/base_layer.py:1044\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1044\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/keras/layers/core.py:913\u001b[0m, in \u001b[0;36mLambda.call\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backprop\u001b[38;5;241m.\u001b[39mGradientTape(watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape,\\\n\u001b[1;32m    912\u001b[0m     variable_scope\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m--> 913\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py:1142\u001b[0m, in \u001b[0;36mupsampling2d_nearest\u001b[0;34m(input_tensor, new_size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupsampling2d_nearest\u001b[39m(\n\u001b[1;32m   1136\u001b[0m     input_tensor,\n\u001b[1;32m   1137\u001b[0m     new_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     name,\n\u001b[1;32m   1141\u001b[0m ):\n\u001b[0;32m-> 1142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_nearest_neighbor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/image_ops_impl.py:4758\u001b[0m, in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, name, half_pixel_centers)\u001b[0m\n\u001b[1;32m   4753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresize_nearest_neighbor\u001b[39m(images,\n\u001b[1;32m   4754\u001b[0m                             size,\n\u001b[1;32m   4755\u001b[0m                             align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4756\u001b[0m                             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4757\u001b[0m                             half_pixel_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 4758\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_image_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_nearest_neighbor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m      \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m      \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/gen_image_ops.py:3857\u001b[0m, in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresize_nearest_neighbor_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3858\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3859\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf_pixel_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3860\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/ops/gen_image_ops.py:3895\u001b[0m, in \u001b[0;36mresize_nearest_neighbor_eager_fallback\u001b[0;34m(images, size, align_corners, half_pixel_centers, name, ctx)\u001b[0m\n\u001b[1;32m   3894\u001b[0m half_pixel_centers \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(half_pixel_centers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhalf_pixel_centers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3895\u001b[0m _attr_T, (images,) \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_to_matching_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3896\u001b[0m size \u001b[38;5;241m=\u001b[39m _ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(size, _dtypes\u001b[38;5;241m.\u001b[39mint32)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:254\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m allowed_dtypes:\n\u001b[0;32m--> 254\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;66;03m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;66;03m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;66;03m# picked the wrong type.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1642\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:344\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    343\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03mNote: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:280\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 280\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:305\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/engine/keras_tensor.py:283\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are passing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, an intermediate Keras symbolic \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput/output, to a TF API that does not allow registering custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispatchers, such as `tf.cond`, `tf.function`, gradient tapes, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.map_fn`. Keras Functional model construction only supports \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF API calls that *do* support dispatching, such as `tf.math.add` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `tf.reshape`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther APIs cannot be called directly on symbolic Keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs/outputs. You can work around \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis limitation by putting the operation in a custom Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`call` and calling that layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon this symbolic input/output.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(1, 17, 17, 256), dtype=tf.float32, name=None), name='tf.math.multiply_1843/Mul:0', description=\"created by layer 'tf.math.multiply_1843'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the YOLO11 model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Export the model to TF.js format\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtfjs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates '/yolo11n_web_model'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the exported TF.js model\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/model.py:742\u001b[0m, in \u001b[0;36mModel.export\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/exporter.py:438\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m edgetpu\n\u001b[0;32m--> 438\u001b[0m f[\u001b[38;5;241m5\u001b[39m], keras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/exporter.py:177\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[0;32m--> 177\u001b[0m     f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ultralytics/engine/exporter.py:1056\u001b[0m, in \u001b[0;36mExporter.export_saved_model\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m   1055\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1056\u001b[0m keras_model \u001b[38;5;241m=\u001b[39m \u001b[43monnx2tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# note INT8-FP16 activation bug https://github.com/ultralytics/ultralytics/issues/15873\u001b[39;49;00m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper-tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"per-tensor\" (faster) or \"per-channel\" (slower but more accurate)\u001b[39;49;00m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_group_convolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for end-to-end model compatibility\u001b[39;49;00m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_batchmatmul_unfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for end-to-end model compatibility\u001b[39;49;00m\n\u001b[1;32m   1066\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m yaml_save(f \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/onnx2tf.py:1020\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indicies_is_int64, replace_argmax_to_reducemax_and_indicies_is_float32, replace_argmax_to_fused_argmax_and_indicies_is_int64, replace_argmax_to_fused_argmax_and_indicies_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[1;32m   1018\u001b[0m sanitizing(graph_node)\n\u001b[0;32m-> 1020\u001b[0m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_layers_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_layers_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m op_counta \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/onnx2tf/utils/common_functions.py:376\u001b[0m, in \u001b[0;36mprint_node_info.<locals>.print_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m error(\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlso, for models that include NonMaxSuppression in the post-processing, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtry the -onwdt option.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:2121\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2119\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2120\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2121\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2122\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "\n",
    "# Export the model to TF.js format\n",
    "model.export(format=\"tfjs\")  # creates '/yolo11n_web_model'\n",
    "\n",
    "# Load the exported TF.js model\n",
    "tfjs_model = YOLO(\"./yolo11n_web_model\")\n",
    "\n",
    "# Run inference\n",
    "results = tfjs_model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.99 🚀 Python-3.9.6 torch-2.2.2 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.49...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 35.8s, saved as '/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx' (10.1 MB)\n",
      "\n",
      "Export complete (36.5s)\n",
      "Results saved to \u001b[1m/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx imgsz=640 data=/workspace/RDD2022-3/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.onnx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"/Users/shachafemanoel/Documents/Hazard-Detection/public/object_detecion_model/road_damage_detection_last_version.pt\")\n",
    "model.export(format=\"onnx\", dynamic=True, opset=12, imgsz=640,nms = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
